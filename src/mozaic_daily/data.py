# -*- coding: utf-8 -*-
"""BigQuery data fetching and query execution.

This module executes SQL queries against BigQuery and returns DataFrames.
Supports checkpoint-based caching to disk (parquet files) to avoid
re-querying during development/testing.

SQL queries are generated by QuerySpec.build_query() in queries.py.

Data is organized by platform -> source -> metric:
- Desktop has both 'glean' and 'legacy' sources
- Mobile has only 'glean' source

Functions:
- get_queries(): Build SQL queries for all platform/metric/source combinations
- get_aggregate_data(): Fetch all Desktop and Mobile metrics from BigQuery
"""

from typing import Dict, Optional, Tuple
import pandas as pd
from google.cloud import bigquery
import os
from .config import STATIC_CONFIG
from .queries import QUERY_SPECS, Platform, Metric, TelemetrySource, QuerySpec


def get_queries(
    countries: str,
    testing_mode: bool = False
) -> Dict[str, Dict[str, Dict[str, Tuple[str, QuerySpec]]]]:
    """Build SQL queries for all platform/metric/source combinations.

    Returns:
        Nested dict structure: {platform: {source: {metric: (sql, spec)}}}
        Example:
        {
            'desktop': {
                'glean': {'DAU': (sql_string, QuerySpec), ...},
                'legacy': {'DAU': (sql_string, QuerySpec), ...}
            },
            'mobile': {
                'glean': {'DAU': (sql_string, QuerySpec), ...}
            }
        }
    """
    queries = {
        "desktop": {"glean": {}, "legacy": {}},
        "mobile": {"glean": {}}
    }

    for spec in QUERY_SPECS.values():
        platform = spec.platform.value
        source = spec.telemetry_source.value
        metric = spec.metric.value
        # In testing mode, only return Desktop Glean DAU
        if testing_mode and not (spec.platform == Platform.DESKTOP and spec.telemetry_source == TelemetrySource.GLEAN and spec.metric == Metric.DAU):
            continue

        sql = spec.build_query(countries)

        queries[platform][source][metric] = (sql, spec)
        
    return queries

# Get data
def get_aggregate_data(
    queries: Dict[str, Dict[str, Dict[str, Tuple[str, QuerySpec]]]],
    project: str,
    checkpoints: Optional[bool] = False,
) -> Dict[str, Dict[str, Dict[str, pd.DataFrame]]]:
    """Fetch all metrics from BigQuery with checkpoint support.

    Args:
        queries: Nested dict from get_queries() with structure {platform: {source: {metric: (sql, spec)}}}
        project: BigQuery project ID
        checkpoints: If True, save/load from parquet files

    Returns:
        Nested dict structure: {platform: {source: {metric: DataFrame}}}
    """
    datasets = {
        "desktop": {"glean": {}, "legacy": {}},
        "mobile": {"glean": {}}
    }

    # Use template from STATIC_CONFIG for checkpoint filenames
    filename_template = STATIC_CONFIG['raw_checkpoint_filename_template']

    # Fetch query results and store the raw data
    # Iterate over platform -> source -> metric
    for platform, sources in queries.items():
        for source, metrics in sources.items():
            for metric, (query, spec) in metrics.items():
                checkpoint_filename = filename_template.format(
                    source=source,
                    platform=platform,
                    metric=metric
                )
                df = None
                if checkpoints and os.path.exists(checkpoint_filename):
                    print(f'{spec.data_source.display_name} {metric} exists, loading')
                    df = pd.read_parquet(checkpoint_filename)
                else:
                    print(f"Querying {spec.data_source.display_name} {metric}")
                    print(query)
                    df = bigquery.Client(project).query(query).to_dataframe()
                    if checkpoints:
                        df.to_parquet(checkpoint_filename)
                datasets[platform][source][metric] = df

    return datasets
