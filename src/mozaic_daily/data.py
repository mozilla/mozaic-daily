# -*- coding: utf-8 -*-
"""BigQuery data fetching and query execution.

This module executes SQL queries against BigQuery and returns DataFrames.
Supports checkpoint-based caching to disk (parquet files) to avoid
re-querying during development/testing.

SQL queries are generated by QuerySpec.build_query() in queries.py.

Data is organized by platform -> source -> metric:
- Desktop has both 'glean' and 'legacy' sources
- Mobile has only 'glean' source

Functions:
- get_queries(): Build SQL queries for all platform/metric/source combinations
- get_aggregate_data(): Fetch all Desktop and Mobile metrics from BigQuery
"""

from typing import Dict, Optional, Tuple
import datetime
import pandas as pd
from google.cloud import bigquery
import os
from .config import STATIC_CONFIG
from .queries import (
    QUERY_SPECS, Platform, Metric, TelemetrySource, QuerySpec,
    AvailabilityCheckQuery, get_availability_check_queries,
)


def check_training_data_availability(project: str, training_end_date: str) -> None:
    """Verify that all BigQuery tables have data through training_end_date.

    Runs a fast MAX(date_field) query against each unique table/date combination
    before the full pipeline starts. Raises immediately if any table is behind,
    saving ~90 minutes compared to discovering the issue at validation time.

    This commonly fails when running at 5 PM PST (= 1 AM UTC next day), because
    the Kubernetes pod computes training_end_date in UTC, referencing a date whose
    BigQuery data hasn't landed yet.

    Args:
        project: BigQuery project ID
        training_end_date: Required end date for training data (YYYY-MM-DD)

    Raises:
        ValueError: If any table's most recent data is before training_end_date,
                    with the unavailable table, available date, and a suggested
                    --forecast_start_date to use instead.
    """
    required_date = datetime.date.fromisoformat(training_end_date)
    checks = get_availability_check_queries()
    client = bigquery.Client(project)

    print(f"Pre-flight check: verifying training data is available through {training_end_date}...")

    for check in checks:
        result = client.query(check.sql).to_dataframe()
        max_date_raw = result['max_date'].iloc[0]

        if pd.isna(max_date_raw):
            raise ValueError(
                f"Pre-flight check failed: no data found in {check.table}.\n"
                f"  Date field: {check.date_field}\n"
                f"  Filter: {check.where_clause}\n"
            )

        max_date = pd.to_datetime(max_date_raw).date()

        if max_date < required_date:
            suggested_start = (max_date + datetime.timedelta(days=1)).isoformat()
            raise ValueError(
                f"Pre-flight check failed: training data not yet available.\n"
                f"  Table: {check.table}\n"
                f"  Required through: {training_end_date}\n"
                f"  Available through: {max_date}\n"
                f"\n"
                f"This commonly happens when the UTC date on the Kubernetes pod is ahead\n"
                f"of your local date (e.g., running at 5 PM PST which is 1 AM UTC next day).\n"
                f"\n"
                f"Suggested fix: --forecast_start_date {suggested_start}"
            )

    print(f"Pre-flight check passed: all tables have data through {training_end_date}.")


def get_queries(
    countries: str,
    testing_mode: bool = False
) -> Dict[str, Dict[str, Dict[str, Tuple[str, QuerySpec]]]]:
    """Build SQL queries for all platform/metric/source combinations.

    Args:
        countries: SQL-formatted country string (e.g., "'US', 'CA', 'GB'")
        testing_mode: If True, only query Desktop Glean DAU

    Returns:
        Nested dict structure: {platform: {source: {metric: (sql, spec)}}}
        Example:
        {
            'desktop': {
                'glean': {'DAU': (sql_string, QuerySpec), ...},
                'legacy': {'DAU': (sql_string, QuerySpec), ...}
            },
            'mobile': {
                'glean': {'DAU': (sql_string, QuerySpec), ...}
            }
        }
    """
    queries = {
        "desktop": {"glean": {}, "legacy": {}},
        "mobile": {"glean": {}}
    }

    for spec in QUERY_SPECS.values():
        platform = spec.platform.value
        source = spec.telemetry_source.value
        metric = spec.metric.value
        # In testing mode, only return Desktop Glean DAU
        if testing_mode and not (spec.platform == Platform.DESKTOP and spec.telemetry_source == TelemetrySource.GLEAN and spec.metric == Metric.DAU):
            continue

        sql = spec.build_query(countries)

        queries[platform][source][metric] = (sql, spec)

    return queries

# Get data
def get_aggregate_data(
    queries: Dict[str, Dict[str, Dict[str, Tuple[str, QuerySpec]]]],
    project: str,
    checkpoints: Optional[bool] = False,
) -> Dict[str, Dict[str, Dict[str, pd.DataFrame]]]:
    """Fetch all metrics from BigQuery with checkpoint support.

    Args:
        queries: Nested dict from get_queries() with structure {platform: {source: {metric: (sql, spec)}}}
        project: BigQuery project ID
        checkpoints: If True, save/load from parquet files

    Returns:
        Nested dict structure: {platform: {source: {metric: DataFrame}}}
    """
    datasets = {
        "desktop": {"glean": {}, "legacy": {}},
        "mobile": {"glean": {}}
    }

    # Use template from STATIC_CONFIG for checkpoint filenames
    filename_template = STATIC_CONFIG['raw_checkpoint_filename_template']

    # Calculate total queries for progress tracking
    total_queries = sum(len(metrics) for sources in queries.values() for metrics in sources.values())
    query_num = 0

    # Fetch query results and store the raw data
    # Iterate over platform -> source -> metric
    for platform, sources in queries.items():
        for source, metrics in sources.items():
            for metric, (query, spec) in metrics.items():
                query_num += 1
                checkpoint_filename = filename_template.format(
                    source=source,
                    platform=platform,
                    metric=metric
                )
                df = None
                if checkpoints and os.path.exists(checkpoint_filename):
                    print(f'[{query_num}/{total_queries}] {spec.data_source.display_name} {metric} exists, loading')
                    df = pd.read_parquet(checkpoint_filename)
                else:
                    print(f"[{query_num}/{total_queries}] Querying {spec.data_source.display_name} {metric}")
                    print(query)
                    df = bigquery.Client(project).query(query).to_dataframe()

                    # Check for empty results
                    if df.empty:
                        raise ValueError(
                            f"BigQuery returned 0 rows for {spec.data_source.display_name} {metric}. "
                            f"Check if date range or country filter is too restrictive."
                        )

                    if checkpoints:
                        df.to_parquet(checkpoint_filename)
                datasets[platform][source][metric] = df

    return datasets
